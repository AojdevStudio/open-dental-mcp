// ---- File: mcp-openai-filesearch/src/server.ts (Updated) ----
// Suppress Node.js experimental warnings
process.removeAllListeners('warning');
// import 'dotenv/config'; // Remove redundant dotenv import
import { McpServer, ResourceTemplate } from "@modelcontextprotocol/sdk/server/mcp.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { z } from "zod";
import OpenAI from 'openai';
import dotenv from 'dotenv';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
// Helper to get __dirname in ES modules
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
// More robust .env loading - explicitly specify path from project root
const projectRoot = path.resolve(__dirname, '..', '..'); // Go up from dist, then mcp-openai-filesearch
const envPath = path.resolve(projectRoot, '.env');
console.error(`Attempting to load .env from: ${envPath}`); // Debug line
dotenv.config({ path: envPath, debug: true }); // Add debug: true to see parsing issues
// --- Environment Variable Checks (CRITICAL) ---
if (!process.env.OPENAI_API_KEY) {
    console.error("FATAL: OPENAI_API_KEY environment variable is not set.");
    process.exit(1); // Exit immediately if key is missing
}
if (!process.env.ASSISTANT_ID) {
    // Make this fatal if the query tool is the ONLY purpose of the server
    console.error("FATAL: ASSISTANT_ID environment variable is not set. Cannot query vector store. Ensure an Assistant configured for File Search exists and its ID is in .env.");
    process.exit(1);
    // If other tools/resources exist, just warn:
    // console.warn("Warning: ASSISTANT_ID environment variable is not set. The 'query_vector_store' tool requires an Assistant configured for File Search.");
}
else {
    console.error(`Using Assistant ID: ${process.env.ASSISTANT_ID}`); // Log which assistant is used
}
// Add check for the specific vector store ID
if (!process.env.OPENDENTAL_VECTOR_STORE_ID) {
    console.error("FATAL: OPENDENTAL_VECTOR_STORE_ID environment variable is not set in .env. This is required for querying.");
    process.exit(1);
}
else {
    console.error(`Using Assistant ID: ${process.env.ASSISTANT_ID}`);
    console.error(`Targeting OpenDental Vector Store ID: ${process.env.OPENDENTAL_VECTOR_STORE_ID}`); // Log the target store
}
// --- OpenAI Client Initialization ---
const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
    defaultHeaders: {
        'OpenAI-Beta': 'assistants=v2' // Correct header for v2
    }
});
console.error("OpenAI client initialized with v2 headers.");
// --- MCP Server Initialization ---
const server = new McpServer({
    name: "openai-file-search",
    version: "1.0.0",
    capabilities: {
        tools: { /* Can add schema here if needed */},
        resources: { /* Can add schema here if needed */},
    }
});
console.error("MCP Server 'openai-file-search' initializing...");
const openAIBeta = openai.beta; // Cast for beta access
// 1. Create Vector Store
server.tool("create_vector_store", { name: z.string().describe("A descriptive name for the vector store.") }, async ({ name }) => {
    try {
        console.error(`Attempting to create vector store: ${name}`);
        const vectorStore = await openAIBeta.vectorStores.create({ name });
        console.error(`Successfully created vector store: ${vectorStore.id}`);
        return {
            content: [{ type: "text", text: `Vector store created successfully. ID: ${vectorStore.id}` }],
            data: { vectorStoreId: vectorStore.id }
        };
    }
    catch (error) {
        console.error("Error creating vector store:", error);
        return {
            content: [{ type: "text", text: `Error creating vector store: ${error.message}` }],
            isError: true
        };
    }
});
// 2. Upload File to OpenAI Files API
server.tool("upload_file", { filePath: z.string().describe("Path to the local file to upload (relative to project root).") }, async ({ filePath }) => {
    try {
        // Resolve path relative to project root (where .env is expected)
        const projectRoot = path.resolve(__dirname, '..', '..'); // Go up from dist, then mcp-openai-filesearch to point to open-dental-mcp
        const absolutePath = path.resolve(projectRoot, filePath);
        console.error(`Attempting to resolve path: Input='${filePath}', ProjectRoot='${projectRoot}', Absolute='${absolutePath}'`);
        if (!fs.existsSync(absolutePath)) {
            throw new Error(`File not found at resolved path: ${absolutePath}. Make sure the path '${filePath}' is relative to the project root '${projectRoot}'.`);
        }
        console.error(`Attempting to upload file: ${absolutePath}`);
        const file = await openai.files.create({
            file: fs.createReadStream(absolutePath),
            purpose: "assistants", // Correct purpose for vector stores/file search
        });
        console.error(`Successfully uploaded file: ${file.id}`);
        return {
            content: [{ type: "text", text: `File uploaded successfully. File ID: ${file.id}` }],
            data: { fileId: file.id }
        };
    }
    catch (error) {
        console.error("Error uploading file:", error);
        return {
            content: [{ type: "text", text: `Error uploading file: ${error.message}` }],
            isError: true
        };
    }
});
// 3. Add File to Vector Store
server.tool("add_file_to_vector_store", {
    vectorStoreId: z.string().describe("The ID of the vector store."), // Removed default - safer to require it
    fileId: z.string().describe("The ID of the file previously uploaded via 'upload_file'.")
}, async ({ vectorStoreId, fileId }) => {
    if (!vectorStoreId) {
        return { content: [{ type: "text", text: "Error: vectorStoreId parameter is required." }], isError: true };
    }
    try {
        console.error(`Adding file ${fileId} to vector store ${vectorStoreId}`);
        // createAndPoll handles the waiting for 'completed' status
        const fileAssociation = await openAIBeta.vectorStores.files.createAndPoll(vectorStoreId, {
            file_id: fileId
        });
        console.error(`File ${fileId} association status in store ${vectorStoreId}: ${fileAssociation.status}`);
        if (fileAssociation.status !== 'completed') {
            // Optional: Treat non-completed as error or warning
            console.warn(`File ${fileId} may still be processing in store ${vectorStoreId}. Status: ${fileAssociation.status}`);
            // return { content: [{ type: "text", text: `File ${fileId} processing status: ${fileAssociation.status}` }], isError: fileAssociation.status === 'failed' };
        }
        return {
            content: [{ type: "text", text: `File ${fileId} added to vector store ${vectorStoreId}. Final Status: ${fileAssociation.status}` }]
        };
    }
    catch (error) {
        console.error(`Error adding file ${fileId} to vector store ${vectorStoreId}:`, error);
        return {
            content: [{ type: "text", text: `Error adding file to vector store: ${error.message}` }],
            isError: true
        };
    }
});
// 4. Query OpenDental Vector Store (Simplified Tool)
server.tool("query_vector_store", {
    query: z.string().describe("The question to ask about OpenDental documentation."),
}, async ({ query }) => {
    // Get the hardcoded ID from the environment
    const vectorStoreId = process.env.OPENDENTAL_VECTOR_STORE_ID; // Use the specific ID from .env
    try {
        // Log uses the specific ID now
        console.error(`Querying OpenDental store ${vectorStoreId} via Assistant ${process.env.ASSISTANT_ID} with: "${query}"`);
        // Create and run the thread - vectorStoreId is now hardcoded from env
        const run = await openai.beta.threads.createAndRun({
            assistant_id: process.env.ASSISTANT_ID,
            thread: {
                messages: [{ role: "user", content: query }],
            },
            tool_resources: {
                file_search: {
                    // Use the specific ID directly
                    vector_store_ids: [vectorStoreId]
                }
            }
        });
        console.error(`Thread ${run.thread_id} created, Run ${run.id} initiated for OpenDental query.`);
        // --- Poll for Run Completion ---
        let runStatus = await openai.beta.threads.runs.retrieve(run.thread_id, run.id);
        const startTime = Date.now();
        const timeout = 180000; // 3 minutes timeout for potentially long searches
        while (['queued', 'in_progress', 'cancelling'].includes(runStatus.status) && Date.now() - startTime < timeout) {
            await new Promise(resolve => setTimeout(resolve, 2000)); // Wait 2 seconds
            runStatus = await openai.beta.threads.runs.retrieve(run.thread_id, run.id);
            console.error(`Run status (${run.id}): ${runStatus.status}`);
        }
        if (runStatus.status !== 'completed') {
            console.error(`Run ${run.id} failed or timed out. Status: ${runStatus.status}`, runStatus.last_error);
            throw new Error(`Thread run did not complete successfully. Final status: ${runStatus.status}. Last Error: ${runStatus.last_error?.message}`);
        }
        // Retrieve messages added by the assistant during the run
        const messagesPage = await openai.beta.threads.messages.list(run.thread_id, { order: 'asc' } // Removed run_id filter here
        );
        // Filter messages client-side based on the run_id
        const assistantMessages = messagesPage.data.filter(m => m.role === 'assistant' && m.run_id === run.id);
        if (!assistantMessages.length) {
            console.error(`Assistant did not provide a response message for run ${run.id}.`);
            // Check run steps for details: await openai.beta.threads.runs.steps.list(run.thread_id, run.id);
            return { content: [{ type: 'text', text: 'Assistant did not provide a response.' }], isError: true };
        }
        // Combine content and extract citations
        let responseText = '';
        const citations = []; // More detailed citation info
        assistantMessages.forEach(msg => {
            msg.content.forEach(contentBlock => {
                if (contentBlock.type === 'text') {
                    responseText += contentBlock.text.value + '\n';
                    contentBlock.text.annotations?.forEach(annotation => {
                        // Check specifically for file_citation type
                        if (annotation.type === 'file_citation') {
                            citations.push({
                                fileId: annotation.file_citation.file_id,
                                // quote: annotation.file_citation.quote, // May be undefined
                                text: annotation.text, // The text in the response that's cited
                                start_index: annotation.start_index,
                                end_index: annotation.end_index
                            });
                        }
                        // Handle 'file_path' annotations if needed similarly
                    });
                }
                else if (contentBlock.type === 'image_file') {
                    // Handle potential image outputs if your assistant generates them
                    responseText += `[Image File: ${contentBlock.image_file.file_id}]\n`;
                }
            });
        });
        console.error(`OpenDental query successful for run ${run.id}. Response extracted.`);
        return {
            content: [{ type: "text", text: responseText.trim() }],
            data: { citations: citations }
        };
    }
    catch (error) {
        // Log uses the specific ID now
        console.error(`Error querying OpenDental store ${vectorStoreId}:`, error);
        return {
            content: [{ type: "text", text: `Error querying OpenDental store: ${error.message}` }],
            isError: true
        };
    }
});
// --- MCP Resources (Examples - Keep as is, ensure logging uses console.error) ---
// List Vector Stores
server.resource("list_vector_stores", "vector_stores://", // URI format
async (uri) => {
    try {
        const stores = await openAIBeta.vectorStores.list();
        const storeList = stores.data.map((s) => `- ${s.name} (ID: ${s.id}, Files: ${s.file_counts?.total || 0})`).join('\n'); // Added file counts
        return {
            contents: [{
                    uri: uri.href,
                    mimeType: "text/plain", // Good practice to add MIME type
                    text: `Available Vector Stores:\n${storeList || 'None found.'}`
                }]
        };
    }
    catch (error) {
        console.error("Error listing vector stores:", error);
        return { contents: [{ uri: uri.href, mimeType: "text/plain", text: `Error listing vector stores: ${error.message}` }] };
    }
});
// List Files in a Vector Store (Using ResourceTemplate)
server.resource("list_vector_store_files", new ResourceTemplate("vector_stores://{vectorStoreId}/files", { list: undefined }), async (uri, { vectorStoreId }) => {
    if (!vectorStoreId) {
        return { contents: [{ uri: uri.href, mimeType: "text/plain", text: "Error: vectorStoreId parameter is missing in URI." }] };
    }
    try {
        console.error(`Listing files for vector store: ${vectorStoreId}`);
        const files = await openAIBeta.vectorStores.files.list(vectorStoreId);
        const fileList = files.data.map((f) => `- File ID: ${f.id}, Status: ${f.status}, Size: ${f.usage_bytes} bytes`).join('\n');
        return {
            contents: [{
                    uri: uri.href,
                    mimeType: "text/plain",
                    text: `Files in Vector Store ${vectorStoreId}:\n${fileList || 'None found.'}`
                }]
        };
    }
    catch (error) {
        console.error(`Error listing files for vector store ${vectorStoreId}:`, error);
        return { contents: [{ uri: uri.href, mimeType: "text/plain", text: `Error listing files: ${error.message}` }] };
    }
});
// Optional: Modify or remove this resource if only one store is relevant
server.resource("list_opendental_docs", // More specific name
`vector_stores://${process.env.OPENDENTAL_VECTOR_STORE_ID}/files`, // Use env var in URI template if desired, or hardcode
async (uri) => {
    const vectorStoreId = process.env.OPENDENTAL_VECTOR_STORE_ID;
    if (!vectorStoreId) {
        return { contents: [{ uri: uri.href, mimeType: "text/plain", text: "Error: OPENDENTAL_VECTOR_STORE_ID not configured." }] };
    }
    try {
        console.error(`Listing files for OpenDental vector store: ${vectorStoreId}`);
        const files = await openAIBeta.vectorStores.files.list(vectorStoreId);
        const fileList = files.data.map((f) => `- File ID: ${f.id}, Status: ${f.status}, Size: ${f.usage_bytes} bytes`).join('\n');
        return {
            contents: [{
                    uri: uri.href,
                    mimeType: "text/plain",
                    text: `Files in OpenDental Vector Store (${vectorStoreId}):\n${fileList || 'None found.'}`
                }]
        };
    }
    catch (error) {
        console.error(`Error listing files for OpenDental vector store ${vectorStoreId}:`, error);
        return { contents: [{ uri: uri.href, mimeType: "text/plain", text: `Error listing OpenDental files: ${error.message}` }] };
    }
});
// --- Start Server ---
async function startServer() {
    try {
        const transport = new StdioServerTransport();
        console.error("Connecting transport...");
        await server.connect(transport);
        console.error("MCP Server 'openai-file-search' is running and connected via stdio.");
    }
    catch (error) {
        console.error("Failed to start or connect MCP server:", error);
        process.exit(1);
    }
}
startServer();
